{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-10 19:05:49.221992: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-10 19:05:49.348681: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-10 19:05:49.351704: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-10-10 19:05:49.351719: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-10-10 19:05:50.116602: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-10-10 19:05:50.116776: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-10-10 19:05:50.116786: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to import handlers from core.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from convolution.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from pooling.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from recurrent.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from reshape.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from merge.py: No module named 'torch'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aelabd/RHEED/hls4ml/hls4ml/converters/__init__.py:29: UserWarning: WARNING: Pytorch converter is not enabled!\n",
      "  warnings.warn(\"WARNING: Pytorch converter is not enabled!\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "try:\n",
    "    from keras.layers.merge import _Merge as Merge\n",
    "except Exception:\n",
    "    from keras.layers.merging.base_merge import _Merge as Merge\n",
    "\n",
    "from tensorflow.python.keras.utils import tf_utils\n",
    "from tensorflow.python.ops import math_ops\n",
    "\n",
    "import hls4ml\n",
    "from hls4ml.converters.keras_to_hls import parse_default_keras_layer\n",
    "from hls4ml.model.attributes import ConfigurableAttribute, TypeAttribute\n",
    "from hls4ml.model.types import FixedPrecisionType, RoundingMode, SaturationMode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras frontend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras implementation of a KL layer\n",
    "class KLLoss(Merge):\n",
    "    '''Keras implementation of a KL loss custom layer'''\n",
    "\n",
    "    @tf_utils.shape_type_conversion\n",
    "    def build(self, input_shape):\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def _merge_function(self, inputs):\n",
    "        mean = inputs[0]\n",
    "        log_var = inputs[1]\n",
    "\n",
    "        kl = 1.0 + log_var - math_ops.square(mean) - math_ops.exp(log_var)\n",
    "        kl = -0.5 * math_ops.reduce_mean(kl, axis=-1, keepdims=True)\n",
    "\n",
    "        return kl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hls4ml frontend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hls4ml implementations\n",
    "class HKLLoss(hls4ml.model.layers.Layer):\n",
    "    '''hls4ml implementation of a KL loss custom layer'''\n",
    "\n",
    "    _expected_attributes = [\n",
    "        ConfigurableAttribute('table_size', default=1024),\n",
    "        ConfigurableAttribute('exp_range', default=8),\n",
    "        TypeAttribute('accum'),\n",
    "        TypeAttribute(\n",
    "            'sum',\n",
    "            default=FixedPrecisionType(18, 8, rounding_mode=RoundingMode.RND, saturation_mode=SaturationMode.SAT),\n",
    "        ),\n",
    "        TypeAttribute(\n",
    "            'exp_table',\n",
    "            default=FixedPrecisionType(18, 8, rounding_mode=RoundingMode.RND, saturation_mode=SaturationMode.SAT),\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    def initialize(self):\n",
    "        self.add_output_variable(shape=[1], dim_names=[f'KL_LOSS_{self.index}'])\n",
    "\n",
    "# Templates\n",
    "distance_config_template = \"\"\"struct config{index} : nnet::distance_config {{\n",
    "    static const unsigned n_in = {n_in};\n",
    "    static const unsigned n_out = 1;\n",
    "    typedef {accum_t.name} accum_t;\n",
    "    typedef {sum_t.name} sum_t;\n",
    "    typedef {exp_table_t.name} exp_table_t;\n",
    "    static const unsigned table_size = {table_size};\n",
    "    static constexpr float exp_range = {exp_range};\n",
    "}};\\n\"\"\"\n",
    "distance_function_template = 'nnet::klloss<{input1_t}, {input2_t}, {output_t}, {config}>({input1}, {input2}, {output});'\n",
    "distance_include_list = ['nnet_utils/kl_layer.h']\n",
    "\n",
    "class HKLLossConfigTemplate(hls4ml.backends.template.LayerConfigTemplate):\n",
    "    def __init__(self):\n",
    "        super().__init__(HKLLoss)\n",
    "        self.template = distance_config_template\n",
    "\n",
    "    def format(self, node):\n",
    "        params = self._default_config_params(node)\n",
    "        params['n_in'] = node.get_input_variable(node.inputs[0]).shape[0]\n",
    "        params['n_out'] = 1\n",
    "        return self.template.format(**params)\n",
    "    \n",
    "class HKLLossFunctionTemplate(hls4ml.backends.template.FunctionCallTemplate):\n",
    "    def __init__(self):\n",
    "        super().__init__(HKLLoss, include_header=distance_include_list)\n",
    "        self.template = distance_function_template\n",
    "\n",
    "    def format(self, node):\n",
    "        params = {}\n",
    "        params['config'] = f'config{node.index}'\n",
    "        params['input1_t'] = node.get_input_variable(node.inputs[0]).type.name\n",
    "        params['input2_t'] = node.get_input_variable(node.inputs[1]).type.name\n",
    "        params['output_t'] = node.get_output_variable().type.name\n",
    "        params['input1'] = node.get_input_variable(node.inputs[0]).name\n",
    "        params['input2'] = node.get_input_variable(node.inputs[1]).name\n",
    "        params['output'] = node.get_output_variable().name\n",
    "\n",
    "        return self.template.format(**params)\n",
    "    \n",
    "# Parser for converter\n",
    "def parse_klloss_layer(keras_layer, input_names, input_shapes, data_reader):\n",
    "    assert 'KLLoss' in keras_layer['class_name']\n",
    "\n",
    "    layer = parse_default_keras_layer(keras_layer, input_names)\n",
    "    output_shape = [input_shapes[0][0], 1]\n",
    "\n",
    "    return layer, output_shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_models():\n",
    "    backend = hls4ml.backends.get_backend('Vivado')\n",
    "    try:\n",
    "        # Register the converter for custom Keras layer\n",
    "        hls4ml.converters.register_keras_layer_handler('KLLoss', parse_klloss_layer)\n",
    "\n",
    "        # Register the hls4ml's IR layer\n",
    "        hls4ml.model.layers.register_layer('KLLoss', HKLLoss)\n",
    "\n",
    "        # Register the optimization passes (if any)\n",
    "        \n",
    "\n",
    "        # Register template passes for the given backend\n",
    "        backend.register_template(HKLLossConfigTemplate)\n",
    "        backend.register_template(HKLLossFunctionTemplate)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Register HLS implementation\n",
    "    # p =  os.getcwd() + '/kl_layer.h'\n",
    "    # p = Path(__file__).parent / 'kl_layer.h'\n",
    "    p =  Path(os.getcwd())/'kl_layer.h'\n",
    "    backend.register_source(p)\n",
    "\n",
    "    # Test if it works\n",
    "    # Create a dummy Keras model with KL loss layer\n",
    "    inp = tf.keras.layers.Input(shape=(19, 3, 1))\n",
    "    z_mean = tf.keras.layers.Dense(10)(inp)\n",
    "    z_log_var = tf.keras.layers.Dense(10)(inp)\n",
    "    custom_output = KLLoss()([z_mean, z_log_var])\n",
    "    # create new model\n",
    "    kmodel = tf.keras.models.Model(inputs=inp, outputs=custom_output)\n",
    "    kmodel.summary()\n",
    "\n",
    "    # test on random inputs\n",
    "    x = np.random.randint(-5, 5, (1, 19, 3, 1), dtype='int32')\n",
    "    kres = kmodel(x)\n",
    "\n",
    "    # Create dummy config\n",
    "    config = {}\n",
    "    config['Model'] = {\n",
    "        'Precision': 'ap_fixed<16,6>',\n",
    "        'ReuseFactor': 1,\n",
    "        'ParallelizationFactor': 1,\n",
    "        'Strategy': 'Resource',\n",
    "    }\n",
    "    hmodel = hls4ml.converters.convert_from_keras_model(\n",
    "        kmodel,\n",
    "        output_dir='hls4mlprj_kl_layer',\n",
    "        backend='Vivado',\n",
    "        io_type='io_parallel',\n",
    "        part='xcvu9p-flga2577-2-e',\n",
    "        hls_config=config,\n",
    "    )\n",
    "\n",
    "    hmodel.compile()\n",
    "    return kmodel, hmodel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-10 19:05:52.913762: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 19:05:52.914024: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-10-10 19:05:52.914151: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-10-10 19:05:52.914225: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-10-10 19:05:52.914297: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-10-10 19:05:52.914368: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-10-10 19:05:52.914437: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-10-10 19:05:52.914505: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-10-10 19:05:52.914575: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-10-10 19:05:52.914590: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-10-10 19:05:52.916028: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 19, 3, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 19, 3, 10)    20          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 19, 3, 10)    20          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " kl_loss (KLLoss)               (None, 19, 3, 1)     0           ['dense[0][0]',                  \n",
      "                                                                  'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 40\n",
      "Trainable params: 40\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 19, 3, 1]], output shape: [None, 19, 3, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 19, 3, 1]], output shape: [None, 19, 3, 10]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 19, 3, 1]], output shape: [None, 19, 3, 10]\n",
      "Layer name: kl_loss, layer type: KLLoss, input shapes: [[None, 19, 3, 10], [None, 19, 3, 10]], output shape: [None, 1]\n",
      "Creating HLS model\n",
      "WARNING: Changing pipeline style to \"dataflow\".\n",
      "Writing HLS project\n",
      "\n",
      "\n",
      ":layer: <hls4ml.backends.fpga.fpga_backend.VivadoInput object at 0x7f4168f31300>\n",
      "    var: <hls4ml.backends.fpga.fpga_types.VivadoArrayVariable object at 0x7f4168f316f0>\n",
      "func: None\n",
      "\n",
      "\n",
      ":layer: <hls4ml.backends.fpga.fpga_backend.VivadoPointwiseConv2D object at 0x7f4168f33610>\n",
      "    var: <hls4ml.backends.fpga.fpga_types.VivadoArrayVariable object at 0x7f4168f339d0>\n",
      "func: nnet::pointwise_conv_2d_cl<input_t, layer9_t, config9>(input_1, layer9_out, w9, b9);\n",
      "\n",
      "\n",
      ":layer: <hls4ml.backends.fpga.fpga_backend.VivadoPointwiseConv2D object at 0x7f4168f33220>\n",
      "    var: <hls4ml.backends.fpga.fpga_types.VivadoArrayVariable object at 0x7f4168f33ee0>\n",
      "func: nnet::pointwise_conv_2d_cl<input_t, layer10_t, config10>(input_1, layer10_out, w10, b10);\n",
      "\n",
      "\n",
      ":layer: <hls4ml.backends.fpga.fpga_backend.VivadoHKLLoss object at 0x7f4168f32200>\n",
      "    var: <hls4ml.backends.fpga.fpga_types.VivadoArrayVariable object at 0x7f4168f32aa0>\n",
      "func: nnet::klloss<layer9_t, layer10_t, result_t, config6>(layer9_out, layer10_out, layer6_out);\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "k_model, hls_model = make_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randint(-5, 5, (1, 19, 3, 1), dtype='int32')\n",
    "kres = k_model(x)\n",
    "hres = hls_model.predict(x.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 19, 3, 1), dtype=float32, numpy=\n",
       "array([[[[ 3.2514224 ],\n",
       "         [ 2.0610871 ],\n",
       "         [-0.        ]],\n",
       "\n",
       "        [[ 1.4704463 ],\n",
       "         [ 2.0610871 ],\n",
       "         [ 1.1571666 ]],\n",
       "\n",
       "        [[ 1.4704463 ],\n",
       "         [ 2.0610871 ],\n",
       "         [ 3.2514224 ]],\n",
       "\n",
       "        [[ 1.4704463 ],\n",
       "         [ 2.0610871 ],\n",
       "         [ 0.14069606]],\n",
       "\n",
       "        [[ 2.9574256 ],\n",
       "         [-0.        ],\n",
       "         [ 2.9574256 ]],\n",
       "\n",
       "        [[ 2.9574256 ],\n",
       "         [ 0.5174905 ],\n",
       "         [ 2.9574256 ]],\n",
       "\n",
       "        [[ 3.2514224 ],\n",
       "         [ 1.1571666 ],\n",
       "         [ 0.5174905 ]],\n",
       "\n",
       "        [[-0.        ],\n",
       "         [ 0.13138631],\n",
       "         [ 1.1571666 ]],\n",
       "\n",
       "        [[ 2.0610871 ],\n",
       "         [ 0.5984329 ],\n",
       "         [ 1.4704463 ]],\n",
       "\n",
       "        [[ 2.0610871 ],\n",
       "         [ 2.9574256 ],\n",
       "         [ 0.5174905 ]],\n",
       "\n",
       "        [[ 0.5984329 ],\n",
       "         [ 0.5174905 ],\n",
       "         [ 0.5984329 ]],\n",
       "\n",
       "        [[-0.        ],\n",
       "         [ 2.0610871 ],\n",
       "         [ 2.9574256 ]],\n",
       "\n",
       "        [[ 3.2514224 ],\n",
       "         [ 3.2514224 ],\n",
       "         [ 2.0610871 ]],\n",
       "\n",
       "        [[ 0.13138631],\n",
       "         [ 0.5174905 ],\n",
       "         [ 1.1571666 ]],\n",
       "\n",
       "        [[ 0.13138631],\n",
       "         [ 0.5984329 ],\n",
       "         [ 0.5174905 ]],\n",
       "\n",
       "        [[ 0.5984329 ],\n",
       "         [ 0.13138631],\n",
       "         [ 0.5174905 ]],\n",
       "\n",
       "        [[ 0.5984329 ],\n",
       "         [ 2.0610871 ],\n",
       "         [ 0.5984329 ]],\n",
       "\n",
       "        [[ 2.0610871 ],\n",
       "         [ 0.5984329 ],\n",
       "         [ 1.1571666 ]],\n",
       "\n",
       "        [[ 1.4704463 ],\n",
       "         [ 1.4704463 ],\n",
       "         [ 3.2514224 ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8261719], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[ 2.4252505 ]\n",
      "   [ 1.2349153 ]\n",
      "   [-0.8261719 ]]\n",
      "\n",
      "  [[ 0.6442745 ]\n",
      "   [ 1.2349153 ]\n",
      "   [ 0.33099473]]\n",
      "\n",
      "  [[ 0.6442745 ]\n",
      "   [ 1.2349153 ]\n",
      "   [ 2.4252505 ]]\n",
      "\n",
      "  [[ 0.6442745 ]\n",
      "   [ 1.2349153 ]\n",
      "   [-0.6854758 ]]\n",
      "\n",
      "  [[ 2.1312537 ]\n",
      "   [-0.8261719 ]\n",
      "   [ 2.1312537 ]]\n",
      "\n",
      "  [[ 2.1312537 ]\n",
      "   [-0.30868137]\n",
      "   [ 2.1312537 ]]\n",
      "\n",
      "  [[ 2.4252505 ]\n",
      "   [ 0.33099473]\n",
      "   [-0.30868137]]\n",
      "\n",
      "  [[-0.8261719 ]\n",
      "   [-0.6947856 ]\n",
      "   [ 0.33099473]]\n",
      "\n",
      "  [[ 1.2349153 ]\n",
      "   [-0.22773898]\n",
      "   [ 0.6442745 ]]\n",
      "\n",
      "  [[ 1.2349153 ]\n",
      "   [ 2.1312537 ]\n",
      "   [-0.30868137]]\n",
      "\n",
      "  [[-0.22773898]\n",
      "   [-0.30868137]\n",
      "   [-0.22773898]]\n",
      "\n",
      "  [[-0.8261719 ]\n",
      "   [ 1.2349153 ]\n",
      "   [ 2.1312537 ]]\n",
      "\n",
      "  [[ 2.4252505 ]\n",
      "   [ 2.4252505 ]\n",
      "   [ 1.2349153 ]]\n",
      "\n",
      "  [[-0.6947856 ]\n",
      "   [-0.30868137]\n",
      "   [ 0.33099473]]\n",
      "\n",
      "  [[-0.6947856 ]\n",
      "   [-0.22773898]\n",
      "   [-0.30868137]]\n",
      "\n",
      "  [[-0.22773898]\n",
      "   [-0.6947856 ]\n",
      "   [-0.30868137]]\n",
      "\n",
      "  [[-0.22773898]\n",
      "   [ 1.2349153 ]\n",
      "   [-0.22773898]]\n",
      "\n",
      "  [[ 1.2349153 ]\n",
      "   [-0.22773898]\n",
      "   [ 0.33099473]]\n",
      "\n",
      "  [[ 0.6442745 ]\n",
      "   [ 0.6442745 ]\n",
      "   [ 2.4252505 ]]]], shape=(1, 19, 3, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(kres - hres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rheed_hls4ml_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
