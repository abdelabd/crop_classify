{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "try:\n",
    "    from keras.layers.merge import _Merge as Merge\n",
    "except Exception:\n",
    "    from keras.layers.merging.base_merge import _Merge as Merge\n",
    "\n",
    "from tensorflow.python.keras.utils import tf_utils\n",
    "from tensorflow.python.ops import math_ops\n",
    "\n",
    "import hls4ml\n",
    "from hls4ml.converters.keras_to_hls import parse_default_keras_layer\n",
    "from hls4ml.model.attributes import ConfigurableAttribute, TypeAttribute\n",
    "from hls4ml.model.types import FixedPrecisionType, RoundingMode, SaturationMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/aelabd/RHEED/crop_classify/custom_hls_layer/test_conversions'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras frontend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras implementation of a KL layer\n",
    "class KLLoss(Merge):\n",
    "    '''Keras implementation of a KL loss custom layer'''\n",
    "\n",
    "    @tf_utils.shape_type_conversion\n",
    "    def build(self, input_shape):\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def _merge_function(self, inputs):\n",
    "        mean = inputs[0]\n",
    "        log_var = inputs[1]\n",
    "\n",
    "        kl = 1.0 + log_var - math_ops.square(mean) - math_ops.exp(log_var)\n",
    "        kl = -0.5 * math_ops.reduce_mean(kl, axis=-1, keepdims=True)\n",
    "\n",
    "        return kl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hls4ml frontend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hls4ml implementations\n",
    "class HKLLoss(hls4ml.model.layers.Layer):\n",
    "    '''hls4ml implementation of a KL loss custom layer'''\n",
    "\n",
    "    _expected_attributes = [\n",
    "        ConfigurableAttribute('table_size', default=1024),\n",
    "        ConfigurableAttribute('exp_range', default=8),\n",
    "        TypeAttribute('accum'),\n",
    "        TypeAttribute(\n",
    "            'sum',\n",
    "            default=FixedPrecisionType(18, 8, rounding_mode=RoundingMode.RND, saturation_mode=SaturationMode.SAT),\n",
    "        ),\n",
    "        TypeAttribute(\n",
    "            'exp_table',\n",
    "            default=FixedPrecisionType(18, 8, rounding_mode=RoundingMode.RND, saturation_mode=SaturationMode.SAT),\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    def initialize(self):\n",
    "        self.add_output_variable(shape=[1], dim_names=[f'KL_LOSS_{self.index}'])\n",
    "        \n",
    "# Templates\n",
    "distance_config_template = \"\"\"struct config{index} : nnet::distance_config {{\n",
    "    static const unsigned n_in = {n_in};\n",
    "    static const unsigned n_out = 1;\n",
    "    typedef {accum_t.name} accum_t;\n",
    "    typedef {sum_t.name} sum_t;\n",
    "    typedef {exp_table_t.name} exp_table_t;\n",
    "    static const unsigned table_size = {table_size};\n",
    "    static constexpr float exp_range = {exp_range};\n",
    "}};\\n\"\"\"\n",
    "distance_function_template = 'nnet::klloss<{input1_t}, {input2_t}, {output_t}, {config}>({input1}, {input2}, {output});'\n",
    "distance_include_list = ['nnet_utils/kl_layer.h']\n",
    "\n",
    "class HKLLossConfigTemplate(hls4ml.backends.template.LayerConfigTemplate):\n",
    "    def __init__(self):\n",
    "        super().__init__(HKLLoss)\n",
    "        self.template = distance_config_template\n",
    "\n",
    "    def format(self, node):\n",
    "        params = self._default_config_params(node)\n",
    "        params['n_in'] = node.get_input_variable(node.inputs[0]).shape[0]\n",
    "        params['n_out'] = 1\n",
    "        return self.template.format(**params)\n",
    "    \n",
    "class HKLLossFunctionTemplate(hls4ml.backends.template.FunctionCallTemplate):\n",
    "    def __init__(self):\n",
    "        super().__init__(HKLLoss, include_header=distance_include_list)\n",
    "        self.template = distance_function_template\n",
    "\n",
    "    def format(self, node):\n",
    "        params = {}\n",
    "        params['config'] = f'config{node.index}'\n",
    "        params['input1_t'] = node.get_input_variable(node.inputs[0]).type.name\n",
    "        params['input2_t'] = node.get_input_variable(node.inputs[1]).type.name\n",
    "        params['output_t'] = node.get_output_variable().type.name\n",
    "        params['input1'] = node.get_input_variable(node.inputs[0]).name\n",
    "        params['input2'] = node.get_input_variable(node.inputs[1]).name\n",
    "        params['output'] = node.get_output_variable().name\n",
    "\n",
    "        return self.template.format(**params)\n",
    "    \n",
    "# Parser for converter\n",
    "def parse_klloss_layer(keras_layer, input_names, input_shapes, data_reader):\n",
    "    assert 'KLLoss' in keras_layer['class_name']\n",
    "\n",
    "    layer = parse_default_keras_layer(keras_layer, input_names)\n",
    "\n",
    "    output_shape = [input_shapes[0][0], 1]\n",
    "\n",
    "    return layer, output_shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Register the converter for custom Keras layer\n",
    "    # hls4ml.converters.register_keras_layer_handler('KLLoss', parse_klloss_layer)\n",
    "\n",
    "    # Register the hls4ml's IR layer\n",
    "    hls4ml.model.layers.register_layer('KLLoss', HKLLoss)\n",
    "\n",
    "    # Register the optimization passes (if any)\n",
    "    backend = hls4ml.backends.get_backend('Vivado')\n",
    "\n",
    "    # Register template passes for the given backend\n",
    "    # backend.register_template(HKLLossConfigTemplate)\n",
    "    # backend.register_template(HKLLossFunctionTemplate)\n",
    "\n",
    "    # Register HLS implementation\n",
    "    p =  os.getcwd() + '/kl_layer.h'\n",
    "    # p = Path(__file__).parent / 'kl_layer.h'\n",
    "    backend.register_source(p)\n",
    "\n",
    "    # Test if it works\n",
    "    # Create a dummy Keras model with KL loss layer\n",
    "    inp = tf.keras.layers.Input(shape=(19, 3, 1))\n",
    "    z_mean = tf.keras.layers.Dense(10)(inp)\n",
    "    z_log_var = tf.keras.layers.Dense(10)(inp)\n",
    "    custom_output = KLLoss()([z_mean, z_log_var])\n",
    "    # create new model\n",
    "    kmodel = tf.keras.models.Model(inputs=inp, outputs=custom_output)\n",
    "    kmodel.summary()\n",
    "\n",
    "    # test on random inputs\n",
    "    x = np.random.randint(-5, 5, (1, 19, 3, 1), dtype='int32')\n",
    "    kres = kmodel(x)\n",
    "\n",
    "    # Create dummy config\n",
    "    config = {}\n",
    "    config['Model'] = {\n",
    "        'Precision': 'ap_fixed<16,6>',\n",
    "        'ReuseFactor': 1,\n",
    "        'ParallelizationFactor': 1,\n",
    "        'Strategy': 'Resource',\n",
    "    }\n",
    "    hmodel = hls4ml.converters.convert_from_keras_model(\n",
    "        kmodel,\n",
    "        output_dir='hls4mlprj_kl_layer',\n",
    "        backend='Vivado',\n",
    "        io_type='io_parallel',\n",
    "        part='xcvu9p-flga2577-2-e',\n",
    "        hls_config=config,\n",
    "    )\n",
    "\n",
    "    hmodel.compile()\n",
    "    hres = hmodel.predict(x.astype('float32'))\n",
    "\n",
    "    print('Compare prediction by hls4ml model to Keras one')\n",
    "    print(kres - hres)\n",
    "\n",
    "    print('Building model')\n",
    "    report = hmodel.build(reset=True, csim=False, cosim=True, synth=True, vsynth=True)\n",
    "    # report = hmodel.build(reset=True, csim=True, cosim=True, synth=True, vsynth=True) # For some reason I can't get csim to work\n",
    "    print(report)\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 19, 3, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 19, 3, 10)    20          ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 19, 3, 10)    20          ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " kl_loss_4 (KLLoss)             (None, 19, 3, 1)     0           ['dense_8[0][0]',                \n",
      "                                                                  'dense_9[0][0]']                \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================================\n",
      "Total params: 40\n",
      "Trainable params: 40\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_5, layer type: InputLayer, input shapes: [[None, 19, 3, 1]], output shape: [None, 19, 3, 1]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 19, 3, 1]], output shape: [None, 19, 3, 10]\n",
      "Layer name: dense_9, layer type: Dense, input shapes: [[None, 19, 3, 1]], output shape: [None, 19, 3, 10]\n",
      "Layer name: kl_loss_4, layer type: KLLoss, input shapes: [[None, 19, 3, 10], [None, 19, 3, 10]], output shape: [None, 1]\n",
      "Creating HLS model\n",
      "WARNING: Changing pipeline style to \"dataflow\".\n",
      "Writing HLS project\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Done\n",
      "Compare prediction by hls4ml model to Keras one\n",
      "tf.Tensor(\n",
      "[[[[-0.05859375]\n",
      "   [ 0.07232676]\n",
      "   [ 2.7843275 ]]\n",
      "\n",
      "  [[ 1.1102345 ]\n",
      "   [ 5.066455  ]\n",
      "   [ 2.7843275 ]]\n",
      "\n",
      "  [[ 1.1102345 ]\n",
      "   [ 2.7843275 ]\n",
      "   [ 0.5303127 ]]\n",
      "\n",
      "  [[ 5.066455  ]\n",
      "   [ 0.07232676]\n",
      "   [-0.05859375]]\n",
      "\n",
      "  [[-0.05859375]\n",
      "   [ 1.1102345 ]\n",
      "   [ 0.4599815 ]]\n",
      "\n",
      "  [[ 0.4599815 ]\n",
      "   [ 5.066455  ]\n",
      "   [ 0.4599815 ]]\n",
      "\n",
      "  [[ 2.7843275 ]\n",
      "   [-0.05859375]\n",
      "   [ 2.7843275 ]]\n",
      "\n",
      "  [[ 0.5303127 ]\n",
      "   [ 1.1102345 ]\n",
      "   [ 0.07232676]]\n",
      "\n",
      "  [[ 1.1102345 ]\n",
      "   [ 0.08052787]\n",
      "   [ 0.08052787]]\n",
      "\n",
      "  [[ 0.07232676]\n",
      "   [ 1.3763975 ]\n",
      "   [ 1.1102345 ]]\n",
      "\n",
      "  [[ 5.066455  ]\n",
      "   [ 0.4599815 ]\n",
      "   [ 0.07232676]]\n",
      "\n",
      "  [[ 1.1102345 ]\n",
      "   [-0.05859375]\n",
      "   [ 2.0457323 ]]\n",
      "\n",
      "  [[ 5.066455  ]\n",
      "   [ 5.066455  ]\n",
      "   [ 1.3763975 ]]\n",
      "\n",
      "  [[ 1.3763975 ]\n",
      "   [-0.05859375]\n",
      "   [ 0.08052787]]\n",
      "\n",
      "  [[ 0.08052787]\n",
      "   [ 2.7843275 ]\n",
      "   [ 0.07232676]]\n",
      "\n",
      "  [[ 2.0457323 ]\n",
      "   [ 0.4599815 ]\n",
      "   [ 0.4599815 ]]\n",
      "\n",
      "  [[ 0.07232676]\n",
      "   [ 2.7843275 ]\n",
      "   [ 1.3763975 ]]\n",
      "\n",
      "  [[ 0.5303127 ]\n",
      "   [-0.05859375]\n",
      "   [-0.05859375]]\n",
      "\n",
      "  [[ 5.066455  ]\n",
      "   [ 1.3763975 ]\n",
      "   [ 0.4599815 ]]]], shape=(1, 19, 3, 1), dtype=float32)\n",
      "Building model\n",
      "\n",
      "****** Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.1 (64-bit)\n",
      "  **** SW Build 2552052 on Fri May 24 14:47:09 MDT 2019\n",
      "  **** IP Build 2548770 on Fri May 24 18:01:18 MDT 2019\n",
      "    ** Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.\n",
      "\n",
      "source /tools/Xilinx/Vivado/2019.1/scripts/vivado_hls/hls.tcl -notrace\n",
      "INFO: [HLS 200-10] Running '/tools/Xilinx/Vivado/2019.1/bin/unwrapped/lnx64.o/vivado_hls'\n",
      "INFO: [HLS 200-10] For user 'aelabd' on host 'DESKTOP-Q0UCNGC.' (Linux_x86_64 version 5.15.133.1-microsoft-standard-WSL2) on Thu Oct 10 10:36:38 PDT 2024\n",
      "INFO: [HLS 200-10] On os Ubuntu 24.04 LTS\n",
      "INFO: [HLS 200-10] In directory '/home/aelabd/RHEED/crop_classify/custom_hls_layer/test_conversions/hls4mlprj_kl_layer'\n",
      "Sourcing Tcl script 'build_prj.tcl'\n",
      "INFO: [HLS 200-10] Opening and resetting project '/home/aelabd/RHEED/crop_classify/custom_hls_layer/test_conversions/hls4mlprj_kl_layer/myproject_prj'.\n",
      "INFO: [HLS 200-10] Adding design file 'firmware/myproject.cpp' to the project\n",
      "INFO: [HLS 200-10] Adding test bench file 'myproject_test.cpp' to the project\n",
      "INFO: [HLS 200-10] Adding test bench file 'firmware/weights' to the project\n",
      "INFO: [HLS 200-10] Adding test bench file 'tb_data' to the project\n",
      "INFO: [HLS 200-10] Opening and resetting solution '/home/aelabd/RHEED/crop_classify/custom_hls_layer/test_conversions/hls4mlprj_kl_layer/myproject_prj/solution1'.\n",
      "INFO: [HLS 200-10] Cleaning up the solution database.\n",
      "INFO: [XFORM 203-101] Allowed max sub elements number after partition is 4096.\n",
      "INFO: [XFORM 203-1161] The maximum of name length is set into 80.\n",
      "INFO: [HLS 200-10] Setting target device to 'xcvu9p-flga2577-2-e'\n",
      "INFO: [SYN 201-201] Setting up clock 'default' with a period of 5ns.\n",
      "INFO: [SYN 201-201] Setting up clock 'default' with an uncertainty of 0.625ns.\n",
      "***** C/RTL SYNTHESIS *****\n",
      "INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.\n",
      "INFO: [HLS 200-10] Analyzing design file 'firmware/myproject.cpp' ... \n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:36:78\n",
      "WARNING: [HLS 200-471] Dataflow form checks found 1 issue(s) in file firmware/myproject.cpp\n",
      "INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:13 ; elapsed = 00:00:14 . Memory (MB): peak = 796.031 ; gain = 126.000 ; free physical = 1562 ; free virtual = 32031\n",
      "INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:13 ; elapsed = 00:00:14 . Memory (MB): peak = 796.031 ; gain = 126.000 ; free physical = 1562 ; free virtual = 32031\n",
      "INFO: [HLS 200-10] Starting code transformations ...\n",
      "INFO: [HLS 200-489] Unrolling loop 'PixelInitAccumLoop' (firmware/nnet_utils/nnet_conv2d_resource.h:42) in function 'void nnet::conv_2d_resource_cl<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config10>(FORWARD_REFERENCE*, FORWARD_REFERENCE*, FORWARD_REFERENCE::weight_t*, FORWARD_REFERENCE::bias_t*)' completely with a factor of 1.\n",
      "INFO: [HLS 200-489] Unrolling loop 'PixelMultLoop' (firmware/nnet_utils/nnet_conv2d_resource.h:66) in function 'void nnet::conv_2d_resource_cl<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config10>(FORWARD_REFERENCE*, FORWARD_REFERENCE*, FORWARD_REFERENCE::weight_t*, FORWARD_REFERENCE::bias_t*)' completely with a factor of 1.\n",
      "INFO: [HLS 200-489] Unrolling loop 'PixelResultLoop' (firmware/nnet_utils/nnet_conv2d_resource.h:92) in function 'void nnet::conv_2d_resource_cl<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config10>(FORWARD_REFERENCE*, FORWARD_REFERENCE*, FORWARD_REFERENCE::weight_t*, FORWARD_REFERENCE::bias_t*)' completely with a factor of 1.\n",
      "INFO: [HLS 200-489] Unrolling loop 'PixelInitAccumLoop' (firmware/nnet_utils/nnet_conv2d_resource.h:42) in function 'void nnet::conv_2d_resource_cl<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>(FORWARD_REFERENCE*, FORWARD_REFERENCE*, FORWARD_REFERENCE::weight_t*, FORWARD_REFERENCE::bias_t*)' completely with a factor of 1.\n",
      "INFO: [HLS 200-489] Unrolling loop 'PixelMultLoop' (firmware/nnet_utils/nnet_conv2d_resource.h:66) in function 'void nnet::conv_2d_resource_cl<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>(FORWARD_REFERENCE*, FORWARD_REFERENCE*, FORWARD_REFERENCE::weight_t*, FORWARD_REFERENCE::bias_t*)' completely with a factor of 1.\n",
      "INFO: [HLS 200-489] Unrolling loop 'PixelResultLoop' (firmware/nnet_utils/nnet_conv2d_resource.h:92) in function 'void nnet::conv_2d_resource_cl<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>(FORWARD_REFERENCE*, FORWARD_REFERENCE*, FORWARD_REFERENCE::weight_t*, FORWARD_REFERENCE::bias_t*)' completely with a factor of 1.\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::product::mult<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::product' into 'nnet::conv_2d_resource_cl<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>' (firmware/nnet_utils/nnet_conv2d_resource.h:70).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::product::mult<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::product' into 'nnet::conv_2d_resource_cl<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config10>' (firmware/nnet_utils/nnet_conv2d_resource.h:70).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::conv_2d_resource_cl<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>' into 'nnet::pointwise_conv_2d_cl<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>' (firmware/nnet_utils/nnet_conv2d.h:69).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::conv_2d_resource_cl<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config10>' into 'nnet::pointwise_conv_2d_cl<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config10>' (firmware/nnet_utils/nnet_conv2d.h:69).\n",
      "INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:14 ; elapsed = 00:00:15 . Memory (MB): peak = 796.031 ; gain = 126.000 ; free physical = 1538 ; free virtual = 32011\n",
      "INFO: [HLS 200-10] Checking synthesizability ...\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::cast<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config9_mult>' into 'nnet::pointwise_conv_2d_cl<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>' (firmware/nnet_utils/nnet_conv2d_resource.h:98->firmware/nnet_utils/nnet_conv2d.h:69) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::cast<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config10_mult>' into 'nnet::pointwise_conv_2d_cl<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config10>' (firmware/nnet_utils/nnet_conv2d_resource.h:98->firmware/nnet_utils/nnet_conv2d.h:69) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 2, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:43) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 2, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 8, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 8, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 2, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 1, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 19, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 19, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 19, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 19, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::klloss<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>' (firmware/nnet_utils/kl_layer.h:80) automatically.\n",
      "INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:14 ; elapsed = 00:00:15 . Memory (MB): peak = 860.031 ; gain = 190.000 ; free physical = 1525 ; free virtual = 32000\n",
      "INFO: [XFORM 203-502] Unrolling all loops for pipelining in function 'nnet::klloss<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>' (firmware/nnet_utils/kl_layer.h:37:46).\n",
      "INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'ReuseLoop' (firmware/nnet_utils/nnet_conv2d_resource.h:53) in function 'nnet::pointwise_conv_2d_cl<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config10>' for pipelining.\n",
      "INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'ReuseLoop' (firmware/nnet_utils/nnet_conv2d_resource.h:53) in function 'nnet::pointwise_conv_2d_cl<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>' for pipelining.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-1' (firmware/nnet_utils/kl_layer.h:56) in function 'nnet::klloss<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>' completely with a factor of 19.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-2' (firmware/nnet_utils/kl_layer.h:64) in function 'nnet::klloss<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>' completely with a factor of 19.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-3' (firmware/nnet_utils/kl_layer.h:75) in function 'nnet::klloss<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>' completely with a factor of 19.\n",
      "INFO: [HLS 200-489] Unrolling loop 'InitAccumLoop' (firmware/nnet_utils/nnet_conv2d_resource.h:46) in function 'nnet::pointwise_conv_2d_cl<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config10>' completely with a factor of 10.\n",
      "INFO: [HLS 200-489] Unrolling loop 'MultLoop' (firmware/nnet_utils/nnet_conv2d_resource.h:62) in function 'nnet::pointwise_conv_2d_cl<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config10>' completely with a factor of 10.\n",
      "INFO: [HLS 200-489] Unrolling loop 'ResultLoop' (firmware/nnet_utils/nnet_conv2d_resource.h:96) in function 'nnet::pointwise_conv_2d_cl<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config10>' completely with a factor of 10.\n",
      "INFO: [HLS 200-489] Unrolling loop 'InitAccumLoop' (firmware/nnet_utils/nnet_conv2d_resource.h:46) in function 'nnet::pointwise_conv_2d_cl<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>' completely with a factor of 10.\n",
      "INFO: [HLS 200-489] Unrolling loop 'MultLoop' (firmware/nnet_utils/nnet_conv2d_resource.h:62) in function 'nnet::pointwise_conv_2d_cl<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>' completely with a factor of 10.\n",
      "INFO: [HLS 200-489] Unrolling loop 'ResultLoop' (firmware/nnet_utils/nnet_conv2d_resource.h:96) in function 'nnet::pointwise_conv_2d_cl<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>' completely with a factor of 10.\n",
      "INFO: [XFORM 203-131] Reshaping array 'input_5.V' (firmware/myproject.cpp:8) in dimension 1 completely.\n",
      "INFO: [XFORM 203-131] Reshaping array 'w10.V'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-131] Reshaping array 'w9.V'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer6_out.V' (firmware/myproject.cpp:9) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer9_out.V' (firmware/myproject.cpp:34) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer10_out.V' (firmware/myproject.cpp:38) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'data_buf.V' (firmware/nnet_utils/nnet_conv2d_resource.h:26) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'b9.V'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'acc.V' (firmware/nnet_utils/nnet_conv2d_resource.h:32) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'data_buf.V' (firmware/nnet_utils/nnet_conv2d_resource.h:26) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'b10.V'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'acc.V' (firmware/nnet_utils/nnet_conv2d_resource.h:32) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'kl.V' (firmware/nnet_utils/kl_layer.h:51) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'mean_sq.V' (firmware/nnet_utils/kl_layer.h:53) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'data_buf.V' (firmware/nnet_utils/nnet_conv2d_resource.h:26) in dimension 2 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'acc.V' (firmware/nnet_utils/nnet_conv2d_resource.h:32) in dimension 2 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'data_buf.V' (firmware/nnet_utils/nnet_conv2d_resource.h:26) in dimension 2 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'acc.V' (firmware/nnet_utils/nnet_conv2d_resource.h:32) in dimension 2 completely.\n",
      "WARNING: [XFORM 203-104] Completely partitioning array 'layer9_out.V' (firmware/myproject.cpp:34) accessed through non-constant indices on dimension 1, which may result in long runtime and suboptimal QoR due to large multiplexers. Please consider wrapping the array access into a function or using a register file core instead.\n",
      "WARNING: [XFORM 203-104] Completely partitioning array 'layer10_out.V' (firmware/myproject.cpp:38) accessed through non-constant indices on dimension 1, which may result in long runtime and suboptimal QoR due to large multiplexers. Please consider wrapping the array access into a function or using a register file core instead.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::cast<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config9_mult>' into 'nnet::pointwise_conv_2d_cl<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>' (firmware/nnet_utils/nnet_conv2d_resource.h:98->firmware/nnet_utils/nnet_conv2d.h:69) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::cast<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config10_mult>' into 'nnet::pointwise_conv_2d_cl<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config10>' (firmware/nnet_utils/nnet_conv2d_resource.h:98->firmware/nnet_utils/nnet_conv2d.h:69) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 2, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:43) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 2, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 8, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 8, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 8, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 2, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 1, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 19, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 19, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 19, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 19, nnet::Op_add<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::klloss<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>' (firmware/nnet_utils/kl_layer.h:80) automatically.\n",
      "INFO: [XFORM 203-712] Applying dataflow to function 'myproject', detected/extracted 4 process function(s): \n",
      "\t 'myproject.entry120'\n",
      "\t 'nnet::pointwise_conv_2d_cl<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>'\n",
      "\t 'nnet::pointwise_conv_2d_cl<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config10>'\n",
      "\t 'nnet::klloss<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>'.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (firmware/nnet_utils/nnet_code_gen.h:33:16) to (firmware/nnet_utils/nnet_code_gen.h:265:5) in function 'nnet::fill_buffer_9<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>::fill_buffer'... converting 115 basic blocks.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (firmware/nnet_utils/nnet_code_gen.h:271:16) to (firmware/nnet_utils/nnet_code_gen.h:503:5) in function 'nnet::fill_buffer_10<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config10>::fill_buffer'... converting 115 basic blocks.\n",
      "INFO: [XFORM 203-11] Balancing expressions in function 'nnet::klloss<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>' (firmware/nnet_utils/kl_layer.h:38:1)...18 expression(s) balanced.\n",
      "INFO: [XFORM 203-11] Balancing expressions in function 'nnet::fill_buffer_9<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>::fill_buffer' (firmware/nnet_utils/nnet_code_gen.h:33)...56 expression(s) balanced.\n",
      "INFO: [XFORM 203-11] Balancing expressions in function 'nnet::fill_buffer_10<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config10>::fill_buffer' (firmware/nnet_utils/nnet_code_gen.h:271)...56 expression(s) balanced.\n",
      "INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:21 ; elapsed = 00:00:22 . Memory (MB): peak = 860.793 ; gain = 190.762 ; free physical = 1480 ; free virtual = 31957\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::pointwise_conv_2d_cl<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>' to 'pointwise_conv_2d_cl<ap_fixed,ap_fixed<16,6,5,3,0>,config9>' (firmware/nnet_utils/nnet_conv2d_resource.h:8:13)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::pointwise_conv_2d_cl<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config10>' to 'pointwise_conv_2d_cl<ap_fixed,ap_fixed<16,6,5,3,0>,config10>' (firmware/nnet_utils/nnet_conv2d_resource.h:8:13)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::klloss<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>' to 'klloss<ap_fixed,ap_fixed<16,6,5,3,0>,ap_fixed<16,6,5,3,0>,config6>' (firmware/nnet_utils/kl_layer.h:38:1)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::fill_buffer_9<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>::fill_buffer' to 'fill_buffer' (firmware/nnet_utils/nnet_code_gen.h:33)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::fill_buffer_10<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config10>::fill_buffer' to 'fill_buffer.1' (firmware/nnet_utils/nnet_code_gen.h:275:5)\n",
      "INFO: [XFORM 203-531] Rewinding loop 'PartitionLoop' (firmware/nnet_utils/nnet_conv2d_resource.h:36) in function 'pointwise_conv_2d_cl<ap_fixed,ap_fixed<16,6,5,3,0>,config9>'.\n",
      "INFO: [XFORM 203-531] Rewinding loop 'PartitionLoop' (firmware/nnet_utils/nnet_conv2d_resource.h:36) in function 'pointwise_conv_2d_cl<ap_fixed,ap_fixed<16,6,5,3,0>,config10>'.\n",
      "WARNING: [XFORM 203-561] Ignored multiple trip count directives for loop 'PartitionLoop' in function 'pointwise_conv_2d_cl<ap_fixed,ap_fixed<16,6,5,3,0>,config9>'.\n",
      "WARNING: [XFORM 203-561] Ignored multiple trip count directives for loop 'PartitionLoop' in function 'pointwise_conv_2d_cl<ap_fixed,ap_fixed<16,6,5,3,0>,config10>'.\n",
      "INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:22 ; elapsed = 00:00:23 . Memory (MB): peak = 860.793 ; gain = 190.762 ; free physical = 1426 ; free virtual = 31903\n",
      "INFO: [HLS 200-10] Starting hardware synthesis ...\n",
      "INFO: [HLS 200-10] Synthesizing 'myproject' ...\n",
      "WARNING: [SYN 201-103] Legalizing function name 'myproject.entry120' to 'myproject_entry120'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'pointwise_conv_2d_cl<ap_fixed,ap_fixed<16,6,5,3,0>,config9>' to 'pointwise_conv_2d_cl_ap_fixed_ap_fixed_16_6_5_3_0_config9_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'fill_buffer.1' to 'fill_buffer_1'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'pointwise_conv_2d_cl<ap_fixed,ap_fixed<16,6,5,3,0>,config10>' to 'pointwise_conv_2d_cl_ap_fixed_ap_fixed_16_6_5_3_0_config10_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'klloss<ap_fixed,ap_fixed<16,6,5,3,0>,ap_fixed<16,6,5,3,0>,config6>' to 'klloss_ap_fixed_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config6_s'.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'myproject_entry120' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 23.55 seconds; current allocated memory: 221.671 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.01 seconds; current allocated memory: 221.733 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'fill_buffer' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'fill_buffer'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 2.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.09 seconds; current allocated memory: 222.714 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.13 seconds; current allocated memory: 223.972 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'pointwise_conv_2d_cl_ap_fixed_ap_fixed_16_6_5_3_0_config9_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining loop 'PartitionLoop'.\n",
      "WARNING: [SCHED 204-68] The II Violation in module 'pointwise_conv_2d_cl_ap_fixed_ap_fixed_16_6_5_3_0_config9_s' (Loop: PartitionLoop): Unable to enforce a carried dependence constraint (II = 1, distance = 1, offset = 1)\n",
      "   between 'store' operation ('data_buf_V_0_0_06281_i77_write_ln36', firmware/nnet_utils/nnet_conv2d_resource.h:36->firmware/nnet_utils/nnet_conv2d.h:69->firmware/myproject.cpp:8) of variable 'data_buf_V_0_0_i', firmware/nnet_utils/nnet_conv2d_resource.h:11->firmware/nnet_utils/nnet_conv2d.h:69 on local variable 'data_buf_V_0_0_06281_i77' and 'load' operation ('data_buf_V_0_0_06281_i77_load') on local variable 'data_buf_V_0_0_06281_i77'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 2, Depth = 6.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.27 seconds; current allocated memory: 224.796 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.09 seconds; current allocated memory: 225.545 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'fill_buffer_1' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'fill_buffer.1'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 2.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.21 seconds; current allocated memory: 226.689 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.1 seconds; current allocated memory: 227.988 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'pointwise_conv_2d_cl_ap_fixed_ap_fixed_16_6_5_3_0_config10_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining loop 'PartitionLoop'.\n",
      "WARNING: [SCHED 204-68] The II Violation in module 'pointwise_conv_2d_cl_ap_fixed_ap_fixed_16_6_5_3_0_config10_s' (Loop: PartitionLoop): Unable to enforce a carried dependence constraint (II = 1, distance = 1, offset = 1)\n",
      "   between 'store' operation ('data_buf_V_0_0_06281_i77_write_ln36', firmware/nnet_utils/nnet_conv2d_resource.h:36->firmware/nnet_utils/nnet_conv2d.h:69->firmware/myproject.cpp:8) of variable 'data_buf_V_0_0_i', firmware/nnet_utils/nnet_conv2d_resource.h:11->firmware/nnet_utils/nnet_conv2d.h:69 on local variable 'data_buf_V_0_0_06281_i77' and 'load' operation ('data_buf_V_0_0_06281_i77_load') on local variable 'data_buf_V_0_0_06281_i77'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 2, Depth = 6.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.24 seconds; current allocated memory: 228.679 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.09 seconds; current allocated memory: 229.407 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'klloss_ap_fixed_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config6_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'klloss<ap_fixed,ap_fixed<16,6,5,3,0>,ap_fixed<16,6,5,3,0>,config6>'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 3.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.31 seconds; current allocated memory: 230.967 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.19 seconds; current allocated memory: 232.673 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'myproject' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.25 seconds; current allocated memory: 233.031 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.46 seconds; current allocated memory: 234.052 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'myproject_entry120' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'myproject_entry120'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.35 seconds; current allocated memory: 234.806 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'fill_buffer' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'fill_buffer'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.04 seconds; current allocated memory: 236.717 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'pointwise_conv_2d_cl_ap_fixed_ap_fixed_16_6_5_3_0_config9_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_16s_10ns_26_1_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_16s_10s_26_1_1': 2 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_16s_11ns_26_1_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_16s_11s_26_1_1': 2 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_16s_6ns_22_1_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_16s_9ns_25_1_1': 2 instance(s).\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'pointwise_conv_2d_cl_ap_fixed_ap_fixed_16_6_5_3_0_config9_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.44 seconds; current allocated memory: 243.184 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'fill_buffer_1' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'fill_buffer_1'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.32 seconds; current allocated memory: 247.793 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'pointwise_conv_2d_cl_ap_fixed_ap_fixed_16_6_5_3_0_config10_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_16s_10ns_26_1_1': 4 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_16s_10s_26_1_1': 2 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_16s_11s_26_1_1': 2 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_16s_6ns_22_1_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_16s_9ns_25_1_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'pointwise_conv_2d_cl_ap_fixed_ap_fixed_16_6_5_3_0_config10_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.46 seconds; current allocated memory: 254.225 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'klloss_ap_fixed_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config6_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_16s_16s_26_1_1': 19 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_7ns_16s_23_1_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'klloss_ap_fixed_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config6_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.35 seconds; current allocated memory: 259.795 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'myproject' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/input_5_V' to 'ap_vld'.\n",
      "INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer6_out_0_V' to 'ap_vld'.\n",
      "INFO: [RTGEN 206-500] Setting interface mode on function 'myproject' to 'ap_ctrl_hs'.\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'myproject'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.68 seconds; current allocated memory: 268.020 MB.\n",
      "INFO: [RTMG 210-279] Implementing memory 'klloss_ap_fixed_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config6_s_exp_table1_rom' using block ROMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'input_5_V_c_U(fifo_w912_d2_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'input_5_V_c7_U(fifo_w912_d2_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_0_V_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_1_V_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_2_V_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_3_V_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_4_V_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_5_V_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_6_V_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_7_V_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_8_V_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_9_V_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_10_V_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_11_V_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_12_V_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_13_V_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_14_V_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_15_V_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_16_V_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_17_V_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_18_V_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer10_out_0_V_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer10_out_1_V_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer10_out_2_V_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer10_out_3_V_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer10_out_4_V_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer10_out_5_V_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer10_out_6_V_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer10_out_7_V_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer10_out_8_V_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer10_out_9_V_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer10_out_10_V_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer10_out_11_V_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer10_out_12_V_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer10_out_13_V_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer10_out_14_V_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer10_out_15_V_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer10_out_16_V_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer10_out_17_V_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer10_out_18_V_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'start_for_pointwise_conv_2d_cl_ap_fixed_ap_fixed_16_6_5_3_0_config9_U0_U(start_for_pointwise_conv_2d_cl_ap_fixed_ap_fixed_16_6_5_3_0_config9_U0)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'start_for_pointwise_conv_2d_cl_ap_fixed_ap_fixed_16_6_5_3_0_config10_U0_U(start_for_pointwise_conv_2d_cl_ap_fixed_ap_fixed_16_6_5_3_0_config10_U0)' using Shift Registers.\n",
      "INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:29 ; elapsed = 00:00:31 . Memory (MB): peak = 988.031 ; gain = 318.000 ; free physical = 1347 ; free virtual = 31847\n",
      "INFO: [VHDL 208-304] Generating VHDL RTL for myproject.\n",
      "INFO: [VLOG 209-307] Generating Verilog RTL for myproject.\n",
      "***** C/RTL SYNTHESIS COMPLETED IN 0h0m30s *****\n",
      "***** C/RTL SIMULATION *****\n",
      "INFO: [HLS 200-10] Adding test bench file 'myproject_test.cpp' to the project\n",
      "INFO: [COSIM 212-47] Using XSIM for RTL simulation.\n",
      "INFO: [COSIM 212-14] Instrumenting C test bench ...\n",
      "ERROR: [COSIM 212-24] TB preprocess failed : In file included from /usr/include/features.h:394:0,\n",
      "                 from /tools/Xilinx/Vivado/2019.1/tps/lnx64/gcc-6.2.0/include/c++/6.2.0/x86_64-pc-linux-gnu/bits/os_defines.h:39,\n",
      "                 from /tools/Xilinx/Vivado/2019.1/tps/lnx64/gcc-6.2.0/include/c++/6.2.0/x86_64-pc-linux-gnu/bits/c++config.h:495,\n",
      "                 from /tools/Xilinx/Vivado/2019.1/tps/lnx64/gcc-6.2.0/include/c++/6.2.0/utility:68,\n",
      "                 from /tools/Xilinx/Vivado/2019.1/tps/lnx64/gcc-6.2.0/include/c++/6.2.0/algorithm:60,\n",
      "                 from /home/aelabd/RHEED/crop_classify/custom_hls_layer/test_conversions/hls4mlprj_kl_layer/myproject_test.cpp:1:\n",
      "/usr/include/features-time64.h:20:27: fatal error: bits/wordsize.h: No such file or directory\n",
      " #include <bits/wordsize.h>\n",
      "                           ^\n",
      "compilation terminated.\n",
      "ERROR: [COSIM 212-5] *** C/RTL co-simulation file generation failed. ***\n",
      "24\n",
      "    while executing\n",
      "\"source build_prj.tcl\"\n",
      "    (\"uplevel\" body line 1)\n",
      "    invoked from within\n",
      "\"uplevel \\#0 [list source $arg] \"\n",
      "\n",
      "INFO: [HLS 200-112] Total elapsed time: 31.14 seconds; peak allocated memory: 268.020 MB.\n",
      "INFO: [Common 17-206] Exiting vivado_hls at Thu Oct 10 10:37:09 2024...\n",
      "Vivado synthesis report not found.\n",
      "Implementation report not found.\n",
      "Timing report not found.\n",
      "{'CSynthesisReport': {'TargetClockPeriod': '5.00', 'EstimatedClockPeriod': '4.263', 'BestLatency': '120', 'WorstLatency': '121', 'IntervalMin': '114', 'IntervalMax': '114', 'BRAM_18K': '112', 'DSP': '39', 'FF': '11737', 'LUT': '11603', 'URAM': '0', 'AvailableBRAM_18K': '4320', 'AvailableDSP': '6840', 'AvailableFF': '2364480', 'AvailableLUT': '1182240', 'AvailableURAM': '960'}, 'CosimReport': {'RTL': 'Verilog', 'Status': 'Fail', 'LatencyMin': 'NA', 'LatencyMax': 'NA', 'IntervalMin': 'NA', 'IntervalMax': 'NA'}}\n"
     ]
    }
   ],
   "source": [
    "report = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rheed_hls4ml_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
